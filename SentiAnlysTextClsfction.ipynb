{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis( Text Classification)\n",
    "https://towardsdatascience.com/a-beginners-guide-to-text-classification-with-scikit-learn-632357e16f3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple guide, we’re going to create a machine learning model that will predict whether a movie review is positive or negative. This is known as binary text classification and will help us explore the scikit-learn library while building a basic machine learning model from scratch. These are the topics we’re going to learn in this guide.\n",
    "\n",
    "Table of Contents\n",
    "1. The Dataset and The Problem to Solve\n",
    "2. Preparing The Data\n",
    " - Reading the dataset\n",
    " - Dealing with Imbalanced Classes\n",
    " - Splitting data into train and test set\n",
    "3. Text Representation (Bag of Words)\n",
    " - CountVectorizer\n",
    " - Term Frequency, Inverse Document Frequency (TF-IDF)\n",
    " - Turning our text data into numerical vectors\n",
    "4. Model Selection\n",
    " - Supervised vs Unsupervised learning\n",
    " - Support Vector Machines (SVM)\n",
    " - Decision Tree\n",
    " - Naive Bayes\n",
    " - Logistic Regression\n",
    "5. Model Evaluation\n",
    " - Mean Accuracy\n",
    " - F1 Score\n",
    " - Classification report\n",
    " - Confusion Matrix\n",
    "6. Tuning the Model\n",
    " - GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset and The Problem to Solve\n",
    "we’ll use an IMDB dataset of 50k movie reviews available on Kaggle. The dataset contains 2 columns (review and sentiment) that will help us identify whether a review is positive or negative.\n",
    "https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "<b>Problem formulation:</b> Our goal is to find which machine learning model is best suited to predict sentiment (output) given a movie review (input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "df_review = pd.read_csv('IMDB Dataset.csv')\n",
    "df_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 50000 rows; however, to train our model faster in the following steps, we’re going to take a smaller sample of 10000 rows. This small sample will contain 9000 positive and 1000 negative reviews to make the data imbalanced (so I can teach you undersampling and oversampling techniques in the next step)\n",
    "\n",
    "We’re going to create this small sample with the following code. The name of this imbalanced dataset will bedf_review_imb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_review[df_review['sentiment']=='positive'][:9000]\n",
    "df_negative = df_review[df_review['sentiment']=='negative'][:1000]\n",
    "df_review_imb = pd.concat([df_positive, df_negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Stranded in Space (1972) MST3K version - a ver...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>I happened to catch this supposed \"horror\" fli...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>waste of 1h45 this nasty little film is one to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Warning: This could spoil your movie. Watch it...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>Quite what the producers of this appalling ada...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     One of the other reviewers has mentioned that ...  positive\n",
       "1     A wonderful little production. <br /><br />The...  positive\n",
       "2     I thought this was a wonderful way to spend ti...  positive\n",
       "4     Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5     Probably my all-time favorite movie, a story o...  positive\n",
       "...                                                 ...       ...\n",
       "2000  Stranded in Space (1972) MST3K version - a ver...  negative\n",
       "2005  I happened to catch this supposed \"horror\" fli...  negative\n",
       "2007  waste of 1h45 this nasty little film is one to...  negative\n",
       "2010  Warning: This could spoil your movie. Watch it...  negative\n",
       "2013  Quite what the producers of this appalling ada...  negative\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_imb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Imbalanced Classes\n",
    "In most cases, you’ll have a large amount of data for one class, and much fewer observations for other classes. This is known as imbalanced data because the number of observations per class is not equally distributed.\n",
    "Let’s take a look at how our df_review_imb dataset is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)  \n",
    "barplot = df_review_imb.groupby(['sentiment'], as_index=False).count()\n",
    "ax = sns.barplot(x=barplot['sentiment'], y=barplot['review'], palette='deep',ci=None)\n",
    "ax.set(title='Sentiment', xlabel='review', ylabel='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are more positive than negative reviews in df_review_imb so we have imbalanced data.\n",
    "To resample our data we use the imblearn library. You can either undersample positive reviews or oversample negative reviews (you need to choose based on the data you’re working with). In this case, we’ll use the RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\hpg4-134\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hpg4-134\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.17.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\hpg4-134\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\hpg4-134\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\hpg4-134\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hpg4-134\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Knute Rockne led an extraordinary life and his...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>At the height of the 'Celebrity Big Brother' r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>This is another of Robert Altman's underrated ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>This movie won a special award at Cannes for i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>You'd be forgiven to think a Finnish director ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     Basically there's a family where a little boy ...  negative\n",
       "1     This show was an amazing, fresh & innovative i...  negative\n",
       "2     Encouraged by the positive comments about this...  negative\n",
       "3     Phil the Alien is one of those quirky films wh...  negative\n",
       "4     I saw this movie when I was about 12 when it c...  negative\n",
       "...                                                 ...       ...\n",
       "1995  Knute Rockne led an extraordinary life and his...  positive\n",
       "1996  At the height of the 'Celebrity Big Brother' r...  positive\n",
       "1997  This is another of Robert Altman's underrated ...  positive\n",
       "1998  This movie won a special award at Cannes for i...  positive\n",
       "1999  You'd be forgiven to think a Finnish director ...  positive\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "from imblearn.under_sampling import  RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "df_review_bal, df_review_bal['sentiment']=rus.fit_resample(df_review_imb[['review']],\n",
    "                                                           df_review_imb['sentiment'])\n",
    "df_review_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a new instance of RandomUnderSampler (rus), we add random_state=0 just to control the randomization of the algorithm. Then we resample the imbalanced dataset df_review_imb by fitting rus with rus.fit_resample(x, y) where “x” contains the data which have to be sampled and “y” corresponds to labels for each sample in “x”.\n",
    "After this, x and y are balanced and we’ll store it in a new dataset named df_review_bal. We can compare the imbalanced and balanced dataset with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    9000\n",
      "negative    1000\n",
      "dtype: int64\n",
      "sentiment\n",
      "positive    1000\n",
      "negative    1000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_review_imb.value_counts('sentiment'))\n",
    "print(df_review_bal.value_counts('sentiment'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data before splitting. (already cleaned data)\n",
    "## Splitting data into train and test set\n",
    "Before we work with our data, we need to split it into a train and test set. The train dataset will be used to fit the model, while the test dataset will be used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "We’ll use sklearn’s train_test_split to do the job. In this case, we set 33% to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_review_bal, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train['review'], train['sentiment']\n",
    "test_x, test_y = test['review'], test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representation (Bag of Words)\n",
    "Classifiers and learning algorithms expect numerical feature vectors rather than raw text documents. This is why we need to turn our movie review text into numerical vectors. There are many text representation techniques such as one-hot encoding, bag of words, and wor2vec.\n",
    "\n",
    "For this simple, we’ll use bag of words (BOW) since we care about the frequency of the words in text reviews; however, the order of words is irrelevant. Two common ways to represent bag of words are CountVectorizer and Term Frequency, Inverse Document Frequency (TF-IDF). Before we choose any of them, I’ll give you an easy-to-understand demonstration of how they work.\n",
    "\n",
    "### CountVectorizer\n",
    "The CountVectorizer gives us the frequency of occurrence of words in a document. Let’s consider the following sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>hate</th>\n",
       "      <th>java</th>\n",
       "      <th>love</th>\n",
       "      <th>python</th>\n",
       "      <th>writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>review1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         code  hate  java  love  python  writing\n",
       "review1     2     0     0     2       2        1\n",
       "review2     2     2     2     0       0        1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text = [\"I love writing code in Python. I love Python code\",\n",
    "        \"I hate writing code in Java. I hate Java code\"]\n",
    "\n",
    "df = pd.DataFrame({'review': ['review1', 'review2'], 'text':text})\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "cv_matrix = cv.fit_transform(df['text'])\n",
    "df_dtm = pd.DataFrame(cv_matrix.toarray(), index=df['review'].values, columns=cv.get_feature_names())\n",
    "df_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the numbers inside the matrix represent the number of times each word was mentioned in each review. Words like “love,” “hate,” and “code” have the same frequency (2) in this example.\n",
    "### Term Frequency, Inverse Document Frequency (TF-IDF)\n",
    "The TF-IDF computes “weights” that represents how important a word is to a document in a collection of documents (aka corpus). The TF-IDF value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word.\n",
    "\n",
    "The representation with TF-IDF will look like the picture below for the same text we used before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>hate</th>\n",
       "      <th>java</th>\n",
       "      <th>love</th>\n",
       "      <th>python</th>\n",
       "      <th>writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>review1</th>\n",
       "      <td>0.438501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616298</td>\n",
       "      <td>0.616298</td>\n",
       "      <td>0.21925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review2</th>\n",
       "      <td>0.438501</td>\n",
       "      <td>0.616298</td>\n",
       "      <td>0.616298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.21925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             code      hate      java      love    python  writing\n",
       "review1  0.438501  0.000000  0.000000  0.616298  0.616298  0.21925\n",
       "review2  0.438501  0.616298  0.616298  0.000000  0.000000  0.21925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text = [\"I love writing code in Python. I love Python code\",\n",
    "        \"I hate writing code in Java. I hate Java code\"]\n",
    "\n",
    "df = pd.DataFrame({'review': ['review1', 'review2'], 'text':text})\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['text'])\n",
    "df_dtm = pd.DataFrame(tfidf_matrix.toarray(), index=df['review'].values, columns=tfidf.get_feature_names())\n",
    "df_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike, the previous example the word “code” doesn’t have the same weight as the words “love” or “hate.” This happens because “code” appears in both reviews; therefore, its weight decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning our text data into numerical vectors\n",
    "In our original dataset, we want to identify unique/representative words for positive reviews and negative reviews, so we’ll choose the TF-IDF. To turn text data into numerical vectors with TF-IDF, we write the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1340x20625 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 118834 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "train_x_vector = tfidf.fit_transform(train_x)\n",
    "train_x_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we create a new instance of TfidfVectorizer(tfidf), we removed English stopwords and then fit (finds the internal parameters of a model) and transform (applies the parameters to the data) the train_x (text reviews)\n",
    "\n",
    "The train_x_vector we just created is a sparse matrix with a shape of 1340 reviews and 20625 words (whole vocabulary used in the reviews). You can display this matrix  with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81      I just got back from this free screening, and ...\n",
       "915     Claire Denis's movies seem to fall into one of...\n",
       "1018    One must admit, that Dev has an eye for beauty...\n",
       "380     Mario Lewis of the Competitive Enterprise Inst...\n",
       "1029    The first, and far better, of Kevin Kline's tw...\n",
       "                              ...                        \n",
       "1130    I saw the movie in Izmir as the closing film o...\n",
       "1294    This is a great documentary and above comments...\n",
       "860     Obviously, the comments above that fawn over t...\n",
       "1459    Robert Carlyle excels again. The period was ca...\n",
       "1126    A convict serving time comes forward to give t...\n",
       "Name: review, Length: 1340, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###a_set = set(tfidf.get_feature_names())\n",
    "#number_of_unique_values = len(a_set)\n",
    "#print(number_of_unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>01pm</th>\n",
       "      <th>02</th>\n",
       "      <th>04</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zues</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>æon</th>\n",
       "      <th>élan</th>\n",
       "      <th>émigré</th>\n",
       "      <th>ísnt</th>\n",
       "      <th>ïn</th>\n",
       "      <th>ünfaithful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340 rows × 20625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  007  01pm   02   04   08        10  100  1000  ...  zooming  \\\n",
       "81    0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "915   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "1018  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "380   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.042791  0.0   0.0  ...      0.0   \n",
       "1029  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "...   ...  ...  ...   ...  ...  ...  ...       ...  ...   ...  ...      ...   \n",
       "1130  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "1294  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "860   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "1459  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "1126  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "\n",
       "      zooms  zues  zzzzzzzzzzzzzzzzzz  æon  élan  émigré  ísnt   ïn  \\\n",
       "81      0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "915     0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1018    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "380     0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1029    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "...     ...   ...                 ...  ...   ...     ...   ...  ...   \n",
       "1130    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1294    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "860     0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1459    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1126    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "\n",
       "      ünfaithful  \n",
       "81           0.0  \n",
       "915          0.0  \n",
       "1018         0.0  \n",
       "380          0.0  \n",
       "1029         0.0  \n",
       "...          ...  \n",
       "1130         0.0  \n",
       "1294         0.0  \n",
       "860          0.0  \n",
       "1459         0.0  \n",
       "1126         0.0  \n",
       "\n",
       "[1340 rows x 20625 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(train_x_vector,\n",
    "                                  index=train_x.index,\n",
    "                                  columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above is the weights of each word(column) in the respective observation\n",
    "\n",
    "Finally, let's also transform the test_x_vector, so we can test the accuracy of the model later (we don’t need to fit tfidf again since we already did it with the training data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_vector = tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "In our example, our input (review) and output (sentiment) are clearly identified, so we can say we have labeled input and output data; therefore, we’re dealing with supervised learning.\n",
    "* Regression: They’re used to predict continuous values such as price, salary, age, etc\n",
    "* Classification: They’re used to predict discrete values such as male/female, spam/not spam, positive/negative, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "['positive']\n",
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "print(svc.predict(tfidf.transform(['A good movie'])))\n",
    "print(svc.predict(tfidf.transform(['An excellent movie'])))\n",
    "print(svc.predict(tfidf.transform(['I did not like this movie at all'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_x_vector.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x_vector.toarray())\n",
    "#toarray returns an ndarray; todense returns a matrix. If you want a matrix, use todense; otherwise, use toarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "In this section, we’ll see traditional metrics used to evaluate our models.\n",
    "### Mean Accuracy\n",
    "To obtain the mean accuracy of each model, just use the .score method with the test samples and true labels as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8409090909090909\n",
      "0.6530303030303031\n",
      "0.6348484848484849\n",
      "0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "# svc.score('Test samples', 'True labels')\n",
    "print(svc.score(test_x_vector, test_y))\n",
    "print(dec_tree.score(test_x_vector, test_y))\n",
    "print(gnb.score(test_x_vector.toarray(), test_y))\n",
    "print(log_reg.score(test_x_vector, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM and Logistic Regression perform better than the other two classifiers, with SVM having a slight advantage (84% of accuracy). To show how the other metrics work, we’ll focus only on SVM.\n",
    "###  F1 Score\n",
    "F1 Score is the weighted average of Precision and Recall. Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial. Also, F1 takes into account how the data is distributed, so it’s useful when you have data with imbalance classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "# F1 score reaches its best value at 1 and worst score at 0.\n",
    "f1_score(y_true, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84671533, 0.83464567])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, svc.predict(test_x_vector),\n",
    "         labels=['positive', 'negative'],\n",
    "         average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the F1 score, we need the true labels and predicted labelsf1_score(y_true, y_pred)\n",
    "\n",
    "The scores obtained for positive labels is 0.84, while negative labels is 0.83.\n",
    "### Classification report\n",
    "We can also build a text report showing the main classification metrics that include those calculated before. To obtain the classification report, we need the true labels and predicted labels classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.87      0.85       335\n",
      "    negative       0.85      0.82      0.83       325\n",
      "\n",
      "    accuracy                           0.84       660\n",
      "   macro avg       0.84      0.84      0.84       660\n",
      "weighted avg       0.84      0.84      0.84       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y, \n",
    "                            svc.predict(test_x_vector),\n",
    "                            labels=['positive', 'negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that allows visualization of the performance of an algorithm. This table typically has two rows and two columns that report the number of false positives, false negatives, true positives, and true negatives.\n",
    "\n",
    "To obtain the confusion matrix, we need the true labels and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[290,  45],\n",
       "       [ 60, 265]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(test_y, \n",
    "                            svc.predict(test_x_vector), \n",
    "                            labels=['positive', 'negative'])\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each element of the array represents one of the four squares in the confusion matrix (e.g., our model detected 290 true positives)\n",
    "## Tuning the Model\n",
    "Finally, it’s time to maximize our model’s performance.\n",
    "### GridSearchCV\n",
    "This is technique consists of an exhaustive search on specified parameters in order to obtain the optimum values of hyperparameters. To do so, we write the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [1, 4, 8, 16, 32], 'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#set the parameters\n",
    "parameters = {'C': [1,4,8,16,32] ,'kernel':['linear', 'rbf']}\n",
    "svc = SVC()\n",
    "svc_grid = GridSearchCV(svc,parameters, cv=5)\n",
    "\n",
    "svc_grid.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the code it’s not so different from the one we wrote to fit the SVM model; however, now we specified some parameters to obtain the optimum model.\n",
    "\n",
    "After fitting the model, we obtain the best score, parameters, and estimators with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n",
      "SVC(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "print(svc_grid.best_params_)\n",
    "print(svc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
